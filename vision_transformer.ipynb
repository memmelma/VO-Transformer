{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a548d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "x = torch.rand((4,3,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd810d",
   "metadata": {},
   "source": [
    "# ViT small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0aab6",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2971fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22196584, torch.Size([4, 384]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vits16 = timm.create_model(\"vit_small_patch16_384\", pretrained=True)\n",
    "count_parameters(vits16), vits16.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b552e",
   "metadata": {},
   "source": [
    "## DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ab6147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/memmelma/.cache/torch/hub/facebookresearch_dino_main\n",
      "/home/memmelma/anaconda3/envs/iprl/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/memmelma/anaconda3/envs/iprl/lib/python3.7/site-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21665664, torch.Size([4, 384]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vits16dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "count_parameters(vits16dino), vits16dino(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354a20d",
   "metadata": {},
   "source": [
    "# ViT base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9bc99",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331a5618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86859496, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitb16 = timm.create_model(\"vit_base_patch16_384\", pretrained=True)\n",
    "count_parameters(vitb16), vitb16.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879b968",
   "metadata": {},
   "source": [
    "## DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0448bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/memmelma/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(85798656, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitb16dino = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "count_parameters(vitb16dino), vitb16dino(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8015a",
   "metadata": {},
   "source": [
    "# ViT base hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca97e3",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb42f2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98950952, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitl16res50 = timm.create_model(\"vit_base_r50_s16_384\", pretrained=True)\n",
    "count_parameters(vitl16res50), vitl16res50.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828fadc",
   "metadata": {},
   "source": [
    "## DPT (Omnidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47546998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98950952, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dpt.dpt_depth import DPTDepthModel\n",
    "\n",
    "backbone = 'vitb_rn50_384' # vitl16_384\n",
    "dpt_depth = DPTDepthModel(backbone=backbone)\n",
    "\n",
    "load_depth_omnidata = 'dpt/pretrained_models'\n",
    "assert os.path.exists(load_depth_omnidata), f\"Path doesn't exist: {load_depth_omnidata}!\"\n",
    "pretrained_weights_path = os.path.join(load_depth_omnidata, f'omnidata_rgb2depth_dpt_hybrid.pth')\n",
    "\n",
    "checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n",
    "\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = {}\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        state_dict[k[6:]] = v\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "dpt_depth.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "count_parameters(dpt_depth.pretrained.model), dpt_depth.pretrained.model.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0cc1e",
   "metadata": {},
   "source": [
    "# ViT large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e79d7",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe3788b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304715752, torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitl16res50 = timm.create_model(\"vit_large_patch16_384\", pretrained=True)\n",
    "count_parameters(vitl16res50), vitl16res50.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ca05c",
   "metadata": {},
   "source": [
    "## DPT (Omnidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64230ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304715752, torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dpt.dpt_depth import DPTDepthModel\n",
    "\n",
    "backbone = 'vitl16_384'\n",
    "dpt_depth = DPTDepthModel(backbone=backbone)\n",
    "\n",
    "load_depth_omnidata = 'dpt/pretrained_models'\n",
    "assert os.path.exists(load_depth_omnidata), f\"Path doesn't exist: {load_depth_omnidata}!\"\n",
    "pretrained_weights_path = os.path.join(load_depth_omnidata, f'omnidata_rgb2depth_dpt_large.pth')\n",
    "\n",
    "checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n",
    "\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = {}\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        state_dict[k[6:]] = v\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "dpt_depth.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "count_parameters(dpt_depth.pretrained.model), dpt_depth.pretrained.model.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa085b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
