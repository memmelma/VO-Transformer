{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b78fd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \n",
      "Err:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]    \n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,277 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main i386 Packages [1,843 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [966 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe i386 Packages [2,024 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,195 kB]\n",
      "Reading package lists... Done                                                  \n",
      "W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\n",
      "E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease' is not signed.\n",
      "N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n",
      "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-xlsxwriter is already the newest version (0.9.6-0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 90 not upgraded.\n",
      "\u001b[33mWARNING: The directory '/home/memmel/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /home/memmel/miniconda/envs/pointnav-vo/lib/python3.7/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /home/memmel/miniconda/envs/pointnav-vo/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt-get update -y\n",
    "!apt-get install -y python-xlsxwriter\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20330833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "username = \"memmelma\"\n",
    "project = \"final\" # multi_modal\n",
    "\n",
    "filter_name = \"dino_act_rgb_freeze\"\n",
    "filter_type = \"eval_\"\n",
    "filter_state = \"finished\"\n",
    "\n",
    "metrics = [\"eval_metricssuccess\", \"eval_metricsspl\", \"eval_metricssoftspl\", \"eval_metricsdistance_to_goal\"]\n",
    "\n",
    "configs = [\"config.VO.REGRESS_MODEL.cls_action\", \"config.VO.REGRESS_MODEL.visual_backbone\", \"config.VO.REGRESS_MODEL.pretrain_backbone\", \"config.VO.REGRESS_MODEL.visual_type\"]\n",
    "\n",
    "out_name = \"exp_eval_strip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78c40e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [00:01<00:00, 83.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>config.VO.REGRESS_MODEL.cls_action</th>\n",
       "      <th>config.VO.REGRESS_MODEL.visual_backbone</th>\n",
       "      <th>config.VO.REGRESS_MODEL.pretrain_backbone</th>\n",
       "      <th>config.VO.REGRESS_MODEL.visual_type</th>\n",
       "      <th>eval_metricssuccess</th>\n",
       "      <th>eval_metricsspl</th>\n",
       "      <th>eval_metricssoftspl</th>\n",
       "      <th>eval_metricsdistance_to_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_vit_b_dino_act_rgb_freeze</td>\n",
       "      <td>ldy30iih</td>\n",
       "      <td>finished</td>\n",
       "      <td>True</td>\n",
       "      <td>base</td>\n",
       "      <td>dino</td>\n",
       "      <td>[rgb, top_down_view]</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.084547</td>\n",
       "      <td>0.464224</td>\n",
       "      <td>2.408709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name        id     state  \\\n",
       "0  eval_vit_b_dino_act_rgb_freeze  ldy30iih  finished   \n",
       "\n",
       "  config.VO.REGRESS_MODEL.cls_action config.VO.REGRESS_MODEL.visual_backbone  \\\n",
       "0                               True                                    base   \n",
       "\n",
       "  config.VO.REGRESS_MODEL.pretrain_backbone  \\\n",
       "0                                      dino   \n",
       "\n",
       "  config.VO.REGRESS_MODEL.visual_type  eval_metricssuccess  eval_metricsspl  \\\n",
       "0                [rgb, top_down_view]             0.112676         0.084547   \n",
       "\n",
       "   eval_metricssoftspl  eval_metricsdistance_to_goal  \n",
       "0             0.464224                      2.408709  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive runs\n",
    "\n",
    "run_ids = []\n",
    "run_names = []\n",
    "run_ckpts = []\n",
    "\n",
    "api = wandb.Api(timeout=45)\n",
    "runs = api.runs(f\"{username}/{project}\")\n",
    "\n",
    "runs_df = pd.DataFrame(columns=[\"name\", \"id\", \"state\", *configs, *metrics])\n",
    "\n",
    "for run in tqdm.tqdm(runs):\n",
    "    \n",
    "    if filter_state and run._state != filter_state:\n",
    "        continue\n",
    "    \n",
    "    if filter_type and filter_type not in run.name:\n",
    "        continue\n",
    "        \n",
    "    if filter_name and filter_name not in run.name:\n",
    "        continue\n",
    "    \n",
    "    run_dict = {}\n",
    "    \n",
    "    # add base attributes\n",
    "    run_dict[\"name\"] = run.name.split(\"[\")[0]\n",
    "    run_dict[\"id\"] = run.id \n",
    "    run_dict[\"state\"] = run._state\n",
    "    \n",
    "    # add config\n",
    "    for config in configs:\n",
    "        # traverse config keys\n",
    "        run_config_tmp = run.config\n",
    "        for config_iter in config.split('.'):\n",
    "            run_config_tmp = run_config_tmp[config_iter]\n",
    "        run_dict[config] = run_config_tmp\n",
    "    \n",
    "    # add filter_operation filter_metric\n",
    "    run_history = run.history()\n",
    "    \n",
    "    # add other metrics corresponding to filter_operation filter_metric\n",
    "    for metric in metrics:\n",
    "        # catch models that only evaluate some actions\n",
    "        if metric in run_history.keys():\n",
    "            run_dict[metric] = run_history[metric][0]\n",
    "        else:\n",
    "            run_dict[metric] = -1\n",
    "    \n",
    "    runs_df = runs_df.append(run_dict, ignore_index=True)\n",
    "    \n",
    "runs_df = runs_df.sort_values(by=['name'])\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d01e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exp_eval_mmmae_20220512'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "filename = f\"{out_name}_{dt}\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dbdf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as excel file\n",
    "extension = \".xlsx\"\n",
    "with pd.ExcelWriter(filename+extension) as excel_writer:\n",
    "    runs_df.to_excel(excel_writer, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
