{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd35ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pointnav_vo.config.vo_config.default import get_config as get_vo_config\n",
    "from pointnav_vo.vo import VOTransformerRegressionGeometricInvarianceEngine\n",
    "\n",
    "ACTIONS = {0: \"STOP\", 1: \"MOVE_FORWARD\", 2: \"TURN_LEFT\", 3: \"TURN_RIGHT\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f00014",
   "metadata": {},
   "source": [
    "## extract statistics from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2131c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_vo_config('/datasets/home/memmel/PointNav-VO/configs/vo/vo_pointnav_vit.yaml', [])\n",
    "config.defrost()\n",
    "config.VO.DATASET.TRAIN = config.VO.DATASET.TRAIN_WITH_NOISE\n",
    "config.VO.DATASET.EVAL = config.VO.DATASET.EVAL_WITH_NOISE\n",
    "\n",
    "# set collision and invariance settings\n",
    "config.VO.TRAIN.collision = '-1' # -1 w/ collision\n",
    "config.VO.GEOMETRY.invariance_types = [\"inverse_joint_train\"] # [\"inverse_joint_train\"]\n",
    "config.freeze()\n",
    "\n",
    "# select what to extract\n",
    "with_mean_std = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c8ada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 19:41:43,268 Visual Odometry configs:\n",
      "BASE_TASK_CONFIG_PATH: configs/challenge_pointnav2021.local.rgbd.yaml\n",
      "CHECKPOINT_FOLDER: {{LOG_DIR}}/checkpoints\n",
      "DEBUG: True\n",
      "ENGINE_NAME: vo_transformer_regression_geo_inv_engine\n",
      "EVAL:\n",
      "  EVAL_CKPT_PATH: eval_ckpt.pth\n",
      "  EVAL_WITH_CKPT: True\n",
      "INFO_DIR: {{LOG_DIR}}/infos\n",
      "LOG_DIR: train_log/vit/\n",
      "LOG_FILE: {{LOG_DIR}}/train.log\n",
      "LOG_INTERVAL: 1\n",
      "N_GPUS: -1\n",
      "RESUME_STATE_FILE: resume_train_ckpt.pth\n",
      "RESUME_TRAIN: False\n",
      "TASK_CONFIG:\n",
      "  DATASET:\n",
      "    CONTENT_SCENES: ['*']\n",
      "    DATA_PATH: /scratch/memmel/dataset/habitat_datasets/pointnav/gibson/v2/{split}/{split}.json.gz\n",
      "    SCENES_DIR: /scratch/memmel/dataset/Gibson\n",
      "    SPLIT: train\n",
      "    TYPE: PointNav-v1\n",
      "  ENVIRONMENT:\n",
      "    ITERATOR_OPTIONS:\n",
      "      CYCLE: True\n",
      "      GROUP_BY_SCENE: True\n",
      "      MAX_SCENE_REPEAT_EPISODES: -1\n",
      "      MAX_SCENE_REPEAT_STEPS: 10000\n",
      "      NUM_EPISODE_SAMPLE: -1\n",
      "      SHUFFLE: False\n",
      "      STEP_REPETITION_RANGE: 0.2\n",
      "    MAX_EPISODE_SECONDS: 10000000\n",
      "    MAX_EPISODE_STEPS: 500\n",
      "  PYROBOT:\n",
      "    BASE_CONTROLLER: proportional\n",
      "    BASE_PLANNER: none\n",
      "    BUMP_SENSOR:\n",
      "      TYPE: PyRobotBumpSensor\n",
      "    DEPTH_SENSOR:\n",
      "      CENTER_CROP: False\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 5.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      TYPE: PyRobotDepthSensor\n",
      "      WIDTH: 640\n",
      "    LOCOBOT:\n",
      "      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']\n",
      "      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']\n",
      "      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']\n",
      "    RGB_SENSOR:\n",
      "      CENTER_CROP: False\n",
      "      HEIGHT: 480\n",
      "      TYPE: PyRobotRGBSensor\n",
      "      WIDTH: 640\n",
      "    ROBOT: locobot\n",
      "    ROBOTS: ['locobot']\n",
      "    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']\n",
      "  SEED: 100\n",
      "  SIMULATOR:\n",
      "    ACTION_SPACE_CONFIG: pyrobotnoisy\n",
      "    AGENTS: ['AGENT_0']\n",
      "    AGENT_0:\n",
      "      ANGULAR_ACCELERATION: 12.56\n",
      "      ANGULAR_FRICTION: 1.0\n",
      "      COEFFICIENT_OF_RESTITUTION: 0.0\n",
      "      HEIGHT: 0.88\n",
      "      IS_SET_START_STATE: False\n",
      "      LINEAR_ACCELERATION: 20.0\n",
      "      LINEAR_FRICTION: 0.5\n",
      "      MASS: 32.0\n",
      "      RADIUS: 0.18\n",
      "      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']\n",
      "      START_POSITION: [0, 0, 0]\n",
      "      START_ROTATION: [0, 0, 0, 1]\n",
      "    DEFAULT_AGENT_ID: 0\n",
      "    DEPTH_SENSOR:\n",
      "      HEIGHT: 192\n",
      "      HFOV: 70\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.1\n",
      "      NOISE_MODEL: RedwoodDepthNoiseModel\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [-0.3490659, 0, 0]\n",
      "      POSITION: [0, 0.88, 0]\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      WIDTH: 341\n",
      "    FORWARD_STEP_SIZE: 0.25\n",
      "    HABITAT_SIM_V0:\n",
      "      ALLOW_SLIDING: False\n",
      "      ENABLE_PHYSICS: False\n",
      "      GPU_DEVICE_ID: 0\n",
      "      GPU_GPU: False\n",
      "      PHYSICS_CONFIG_FILE: ./data/default.phys_scene_config.json\n",
      "    NOISE_MODEL:\n",
      "      CONTROLLER: Proportional\n",
      "      NOISE_MULTIPLIER: 0.5\n",
      "      ROBOT: LoCoBot\n",
      "    RGB_SENSOR:\n",
      "      HEIGHT: 192\n",
      "      HFOV: 70\n",
      "      NOISE_MODEL: GaussianNoiseModel\n",
      "      NOISE_MODEL_KWARGS:\n",
      "        intensity_constant: 0.1\n",
      "      ORIENTATION: [-0.3490659, 0, 0]\n",
      "      POSITION: [0, 0.88, 0]\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      WIDTH: 341\n",
      "    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb\n",
      "    SEED: 100\n",
      "    TILT_ANGLE: 15\n",
      "    TURN_ANGLE: 30\n",
      "    TYPE: Sim-v0\n",
      "  TASK:\n",
      "    ACTIONS:\n",
      "      LOOK_DOWN:\n",
      "        TYPE: LookDownAction\n",
      "      LOOK_UP:\n",
      "        TYPE: LookUpAction\n",
      "      MOVE_FORWARD:\n",
      "        TYPE: MoveForwardAction\n",
      "      STOP:\n",
      "        TYPE: StopAction\n",
      "      TELEPORT:\n",
      "        TYPE: TeleportAction\n",
      "      TURN_LEFT:\n",
      "        TYPE: TurnLeftAction\n",
      "      TURN_RIGHT:\n",
      "        TYPE: TurnRightAction\n",
      "    COLLISIONS:\n",
      "      TYPE: Collisions\n",
      "    COMPASS_SENSOR:\n",
      "      TYPE: CompassSensor\n",
      "    DISTANCE_TO_GOAL:\n",
      "      DISTANCE_TO: POINT\n",
      "      TYPE: DistanceToGoal\n",
      "    GOAL_SENSOR_UUID: pointgoal\n",
      "    GPS_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      TYPE: GPSSensor\n",
      "    HEADING_SENSOR:\n",
      "      TYPE: HeadingSensor\n",
      "    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']\n",
      "    POINTGOAL_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      GOAL_FORMAT: POLAR\n",
      "      TYPE: PointGoalSensor\n",
      "    POINTGOAL_WITH_GPS_COMPASS_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      GOAL_FORMAT: POLAR\n",
      "      TYPE: PointGoalWithGPSCompassSensor\n",
      "    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT']\n",
      "    PROXIMITY_SENSOR:\n",
      "      MAX_DETECTION_RADIUS: 2.0\n",
      "      TYPE: ProximitySensor\n",
      "    SENSORS: ['POINTGOAL_SENSOR']\n",
      "    SOFT_SPL:\n",
      "      TYPE: SoftSPL\n",
      "    SPL:\n",
      "      TYPE: SPL\n",
      "    SUCCESS:\n",
      "      SUCCESS_DISTANCE: 0.36\n",
      "      TYPE: Success\n",
      "    SUCCESS_DISTANCE: 0.36\n",
      "    TOP_DOWN_MAP:\n",
      "      DRAW_BORDER: True\n",
      "      DRAW_GOAL_AABBS: True\n",
      "      DRAW_GOAL_POSITIONS: True\n",
      "      DRAW_SHORTEST_PATH: True\n",
      "      DRAW_SOURCE: True\n",
      "      DRAW_VIEW_POINTS: True\n",
      "      FOG_OF_WAR:\n",
      "        DRAW: True\n",
      "        FOV: 70\n",
      "        VISIBILITY_DIST: 5.0\n",
      "      MAP_PADDING: 3\n",
      "      MAP_RESOLUTION: 1250\n",
      "      MAX_EPISODE_STEPS: 1000\n",
      "      NUM_TOPDOWN_MAP_SAMPLE_POINTS: 20000\n",
      "      TYPE: TopDownMap\n",
      "    TYPE: Nav-v0\n",
      "TENSORBOARD_DIR: {{LOG_DIR}}/tb\n",
      "VIDEO_DIR: {{LOG_DIR}}/videos\n",
      "VIDEO_OPTION: []\n",
      "VO:\n",
      "  DATASET:\n",
      "    EVAL: /scratch/memmel/dataset/val_25000.h5\n",
      "    EVAL_WITH_NOISE: /scratch/memmel/dataset/val_25000.h5\n",
      "    PARTIAL_DATA_N_SPLITS: 1\n",
      "    TRAIN: /scratch/memmel/dataset/train_250000.h5\n",
      "    TRAIN_WITH_NOISE: /scratch/memmel/dataset/train_250000.h5\n",
      "  EVAL:\n",
      "    eval_acts: ['no_specify']\n",
      "    rank_pred: False\n",
      "    rank_top_k: 20\n",
      "    save_pred: True\n",
      "  GEOMETRY:\n",
      "    invariance_types: ['inverse_joint_train']\n",
      "    loss_inv_weight: 1\n",
      "  MODEL:\n",
      "    cls_action: True\n",
      "    discretize_depth: none\n",
      "    discretized_depth_channels: 0\n",
      "    dropout_p: 0\n",
      "    hidden_size: 512\n",
      "    name: vo_transformer_act_embed\n",
      "    omnidata_model_path: dpt/pretrained_models\n",
      "    pretrain_backbone: None\n",
      "    pretrained: False\n",
      "    pretrained_ckpt:\n",
      "      forward: ckpt_forward.pth\n",
      "      left: act_left.pth\n",
      "      right: act_right.pth\n",
      "    top_down_center_crop: False\n",
      "    train_backbone: True\n",
      "    visual_backbone: small\n",
      "    visual_type: []\n",
      "  REGRESSION:\n",
      "    delta_types: ['dx', 'dz', 'dyaw']\n",
      "  TRAIN:\n",
      "    action_type: -1\n",
      "    backbone_lr: 0.0002\n",
      "    batch_size: 64\n",
      "    collision: -1\n",
      "    depth_aux_loss: 0.0\n",
      "    epochs: 150\n",
      "    eps: 1e-08\n",
      "    log_grad: False\n",
      "    log_grad_interval: 200\n",
      "    loss_weight_fixed: True\n",
      "    loss_weight_multiplier:\n",
      "      dx: 1.0\n",
      "      dyaw: 1.0\n",
      "      dz: 1.0\n",
      "    lr: 0.0002\n",
      "    max_clip_gradient_norm: 1.0\n",
      "    mixed_precision: True\n",
      "    optim: adamw\n",
      "    scheduler: none\n",
      "    warm_up_steps: 10\n",
      "    weight_decay: 0.0\n",
      "  VIS_SIZE_H: 192\n",
      "  VIS_SIZE_W: 341\n",
      "  VO_TYPE: REGRESS\n",
      "2022-03-02 19:41:43,324 \n",
      "Dataset: chunk bytes 159.84378814697266 MB\n",
      "\n",
      "2022-03-02 19:41:43,325 Get index mapping from h5py ...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 977/977 [00:03<00:00, 292.61it/s]\n",
      "2022-03-02 19:41:46,677 ... done. lenght 250000\n",
      "\n",
      "2022-03-02 19:41:46,688 \n",
      "Dataset: chunk bytes 159.84378814697266 MB\n",
      "\n",
      "2022-03-02 19:41:46,688 Get index mapping from h5py ...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:00<00:00, 340.61it/s]\n",
      "2022-03-02 19:41:46,980 ... done. lenght 25000\n",
      "\n",
      "2022-03-02 19:41:46,982 \n",
      "Dataset: chunk bytes 159.84378814697266 MB\n",
      "\n",
      "2022-03-02 19:41:46,982 Get index mapping from h5py ...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:00<00:00, 1839.49it/s]\n",
      "2022-03-02 19:41:47,040 ... done. lenght 14008\n",
      "\n",
      "2022-03-02 19:41:47,043 \n",
      "Dataset: chunk bytes 159.84378814697266 MB\n",
      "\n",
      "2022-03-02 19:41:47,043 Get index mapping from h5py ...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:00<00:00, 1939.42it/s]\n",
      "2022-03-02 19:41:47,096 ... done. lenght 5557\n",
      "\n",
      "2022-03-02 19:41:47,098 \n",
      "Dataset: chunk bytes 159.84378814697266 MB\n",
      "\n",
      "2022-03-02 19:41:47,098 Get index mapping from h5py ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:00<00:00, 1938.05it/s]\n",
      "2022-03-02 19:41:47,152 ... done. lenght 5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine = VOTransformerRegressionGeometricInvarianceEngine(config=config, run_type='train')\n",
    "engine._set_up_dataloader(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ded87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "796it [03:48,  5.21it/s]"
     ]
    }
   ],
   "source": [
    "data = dict({\n",
    "    'actions': [],\n",
    "    'delta_xs': [],\n",
    "    'delta_ys': [],\n",
    "    'delta_zs': [],\n",
    "    'delta_yaws': [],\n",
    "    'dz_regress_masks': [],\n",
    "    })\n",
    "mean, std = torch.zeros(3), torch.zeros(3)\n",
    "ctr = 0\n",
    "samples = 0\n",
    "\n",
    "train_iter = iter(engine.train_loader)\n",
    "with tqdm(total=0) as pbar:\n",
    "            \n",
    "    while True:\n",
    "        try:\n",
    "            batch_data = next(train_iter)\n",
    "        # NOTE RuntimeError: DataLoader timed out after 300 seconds\n",
    "        except RuntimeError  as re:\n",
    "            print(re)\n",
    "            batch_data = next(train_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        (data_types,\n",
    "        raw_rgb_pairs,\n",
    "        raw_depth_pairs,\n",
    "        raw_discretized_depth_pairs,\n",
    "        raw_top_down_view_pairs,\n",
    "\n",
    "        actions,\n",
    "        delta_xs,\n",
    "        delta_ys,\n",
    "        delta_zs,\n",
    "        delta_yaws,\n",
    "        dz_regress_masks,\n",
    "\n",
    "        chunk_idxs,\n",
    "        entry_idxs,\n",
    "        ) = batch_data\n",
    "       \n",
    "        data['actions'].append(actions)\n",
    "        data['delta_xs'].append(delta_xs)\n",
    "        data['delta_ys'].append(delta_ys)\n",
    "        data['delta_zs'].append(delta_zs)\n",
    "        data['delta_yaws'].append(delta_yaws)\n",
    "        data['dz_regress_masks'].append(dz_regress_masks)\n",
    "        \n",
    "        if with_mean_std:\n",
    "            rgb = torch.cat([torch.cat((pair[:,:,:,:pair.shape[-1]//2], pair[:,:,:,pair.shape[-1]//2:]),dim=0).float().to(torch.device('cpu'), non_blocking=True)\n",
    "                            for pair in raw_rgb_pairs], dim=0,)\n",
    "\n",
    "            mean += (torch.mean(rgb, axis=(0,1,2)) / 255.)\n",
    "            std += (torch.std(rgb, axis=(0,1,2)) / 255.)\n",
    "            ctr += 1\n",
    "            samples += rgb.shape[0]\n",
    "            \n",
    "        pbar.update(1)\n",
    "        \n",
    "for k in data.keys():\n",
    "    data[k] = torch.cat(data[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96910186",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f398ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp['actions'].unique(), data_tmp['actions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ce739",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = './plots'\n",
    "os.makedirs(outpath,exist_ok=True)\n",
    "fname_append = f\"{'_collision' if config.VO.TRAIN.collision == '-1' else ''}{'_invjoint' if 'inverse_joint_train' in config.VO.GEOMETRY.invariance_types else ''}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outpath,'statistics'+fname_append+'.txt'), 'w') as f:\n",
    "    f.write(f'mean {(mean / ctr).tolist()}\\n')\n",
    "    f.write(f'std {(std / ctr).tolist()}\\n')\n",
    "    f.write(f'samples ALL {int(samples)}\\n')\n",
    "    for act in ACTIONS:\n",
    "        f.write(f'samples {ACTIONS[act]} {(data_tmp[\"actions\"]==act).sum()}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "barlist = plt.bar(x=[0,1,2], height=[(data_tmp['actions']==act).sum() for act in data_tmp['actions'].unique()])\n",
    "barlist[0].set_color('tab:blue')\n",
    "barlist[1].set_color('tab:green')\n",
    "barlist[2].set_color('tab:orange')\n",
    "\n",
    "plt.xticks([])\n",
    "plt.title(f'{\"w/\" if config.VO.TRAIN.collision == \"-1\" else \"w/o\"} collisions')\n",
    "\n",
    "plt.savefig(os.path.join(outpath,'bar'+fname_append+'.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210da801",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict({\n",
    "    'delta_xs': r'$\\xi^x_{C_t\\rightarrow C_{t+1}}$',\n",
    "    'delta_zs': r'$\\xi^z_{C_t\\rightarrow C_{t+1}}$',\n",
    "    'delta_yaws': r'$\\theta_{C_t\\rightarrow C_{t+1}}$',\n",
    "})\n",
    "\n",
    "plots = [('delta_xs', 'delta_zs'), ('delta_xs', 'delta_yaws'), ('delta_zs', 'delta_yaws')]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,4)\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "\n",
    "for i, (kx,ky) in enumerate(plots):\n",
    "    for act in data_tmp['actions'].unique():\n",
    "        selector = data_tmp['actions']==act\n",
    "        axs[i].scatter(data_tmp[kx][selector],\n",
    "                    data_tmp[ky][selector],\n",
    "                    label=ACTIONS[act.item()], s=2)\n",
    "\n",
    "    axs[i].set_xlabel(label_dict[kx], fontsize=20)\n",
    "    axs[i].set_ylabel(label_dict[ky], fontsize=20)\n",
    "\n",
    "    axs[i].tick_params(labelsize=10)\n",
    "\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outpath,'distributions'+fname_append+'.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fc01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
