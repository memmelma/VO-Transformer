{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85dc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_all_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "x = torch.rand((4,3,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fa544",
   "metadata": {},
   "source": [
    "# Possible Speedup (didn't really work so far)\n",
    "https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2f0f32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vits16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vits16' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vits16.eval()\n",
    "for i in range(25):\n",
    "    vits16(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56922572",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.jit' has no attribute 'optimize_for_inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.jit' has no attribute 'optimize_for_inference'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frozen_mod = torch.jit.optimize_for_inference(torch.jit.script(vits16.eval()))\n",
    "for i in range(25):\n",
    "    frozen_mod.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a6195",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3daab364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/memmel/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11689512, torch.Size([4, 512, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = timm.create_model(\"resnet18\", pretrained=True)\n",
    "count_parameters(resnet18), resnet18.forward_features(x).shape, resnet18.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4df78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth\" to /home/memmel/.cache/torch/hub/checkpoints/resnet50_a1_0-14fe96d1.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25557032, torch.Size([4, 2048, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = timm.create_model(\"resnet50\", pretrained=True)\n",
    "count_parameters(resnet50), resnet50.forward_features(x).shape, resnet50.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4479d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44549160, torch.Size([4, 2048, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet101 = timm.create_model(\"resnet101\", pretrained=True)\n",
    "count_parameters(resnet101), resnet101.forward_features(x).shape, resnet101.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45aba28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60192808, torch.Size([4, 2048, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet152 = timm.create_model(\"resnet152\", pretrained=True)\n",
    "count_parameters(resnet152), resnet152.forward_features(x).shape, resnet152.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6212c64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist for this model. Using random initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64673832, torch.Size([4, 2048, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet200 = timm.create_model(\"resnet200\", pretrained=True)\n",
    "count_parameters(resnet200), resnet200.forward_features(x).shape, resnet200.forward(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642db9d2",
   "metadata": {},
   "source": [
    "# ConvNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee186f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\" to /home/memmel/.cache/torch/hub/checkpoints/convnext_tiny_1k_224_ema.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28589128, torch.Size([4, 768, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext_tiny = timm.create_model(\"convnext_tiny\", pretrained=True)\n",
    "count_parameters(convnext_tiny), convnext_tiny.forward_features(x).shape, convnext_tiny.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1617319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\" to /home/memmel/.cache/torch/hub/checkpoints/convnext_small_1k_224_ema.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50223688, torch.Size([4, 768, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext_small = timm.create_model(\"convnext_small\", pretrained=True)\n",
    "count_parameters(convnext_small), convnext_small.forward_features(x).shape, convnext_small.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d729ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth\" to /home/memmel/.cache/torch/hub/checkpoints/convnext_base_1k_224_ema.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88591464, torch.Size([4, 1024, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext_base = timm.create_model(\"convnext_base\", pretrained=True)\n",
    "count_parameters(convnext_base), convnext_base.forward_features(x).shape, convnext_base.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139f3512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197767336, torch.Size([4, 1536, 12, 12]), torch.Size([4, 1000]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext_large = timm.create_model(\"convnext_large\", pretrained=True)\n",
    "count_parameters(convnext_large), convnext_large.forward_features(x).shape, convnext_large.forward(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b27f7",
   "metadata": {},
   "source": [
    "# ViT small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33216bc1",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4948ab5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22196584, torch.Size([4, 384]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vits16 = timm.create_model(\"vit_small_patch16_384\", pretrained=True)\n",
    "count_parameters(vits16), vits16.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6351bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050664, torch.Size([4, 384]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4,3,224,224))\n",
    "vits16 = timm.create_model(\"vit_small_patch16_224\", pretrained=True)\n",
    "count_parameters(vits16), vits16.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5b6b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30075219, 30075219, torch.Size([4, 197, 384]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4,3,224,224))\n",
    "vits16_in21k = timm.create_model(\"vit_small_patch16_224_in21k\", pretrained=True)\n",
    "count_parameters(vits16_in21k), count_all_parameters(vits16_in21k), vits16_in21k.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8192f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list_vits16_in21k = []\n",
    "param_list_vits16_in21k = []\n",
    "for name, module in vits16_in21k.named_modules():\n",
    "    module_list_vits16_in21k += [name]\n",
    "    tmp = 0\n",
    "    for p in module.parameters():\n",
    "        tmp += p.numel()\n",
    "    param_list_vits16_in21k += [tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98629f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21665664, 21665664, torch.Size([4, 197, 384]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4,3,224,224))\n",
    "vits16dino = timm.create_model(\"vit_small_patch16_224_dino\", pretrained=True)\n",
    "count_parameters(vits16dino), count_all_parameters(vits16dino), vits16dino.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b864c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list_vits16_dino = []\n",
    "param_list_vits16_dino = []\n",
    "for name, module in vits16dino.named_modules():\n",
    "    module_list_vits16_dino += [name]\n",
    "    tmp = 0\n",
    "    for p in module.parameters():\n",
    "        tmp += p.numel()\n",
    "    param_list_vits16_dino += [tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd307b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 225, 225, 225)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(module_list_vits16_in21k), len(module_list_vits16_dino), len(param_list_vits16_in21k), len(param_list_vits16_dino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70a54f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,      768,   147840,   295296,   443520,   590208,\n",
       "         591360,  1181568,  1774464, 21293568])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.intersect1d(param_list_vits16_in21k, param_list_vits16_dino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf1a66",
   "metadata": {},
   "source": [
    "## DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e71113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/memmelma/.cache/torch/hub/facebookresearch_dino_main\n",
      "/home/memmelma/anaconda3/envs/iprl/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/memmelma/anaconda3/envs/iprl/lib/python3.7/site-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21665664, torch.Size([4, 384]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vits16dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "count_parameters(vits16dino), vits16dino(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7c8b3",
   "metadata": {},
   "source": [
    "# ViT base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb82ed",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f00c4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86859496, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitb16 = timm.create_model(\"vit_base_patch16_384\", pretrained=True)\n",
    "count_parameters(vitb16), vitb16.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae5081",
   "metadata": {},
   "source": [
    "## DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cf2727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/memmelma/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(85798656, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitb16dino = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "count_parameters(vitb16dino), vitb16dino(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ae761",
   "metadata": {},
   "source": [
    "# ViT base hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b10827",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0423a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98950952, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitl16res50 = timm.create_model(\"vit_base_r50_s16_384\", pretrained=True)\n",
    "count_parameters(vitl16res50), vitl16res50.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a1ffe",
   "metadata": {},
   "source": [
    "## DPT (Omnidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c529a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98950952, torch.Size([4, 768]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dpt.dpt_depth import DPTDepthModel\n",
    "\n",
    "backbone = 'vitb_rn50_384' # vitl16_384\n",
    "dpt_depth = DPTDepthModel(backbone=backbone)\n",
    "\n",
    "load_depth_omnidata = 'dpt/pretrained_models'\n",
    "assert os.path.exists(load_depth_omnidata), f\"Path doesn't exist: {load_depth_omnidata}!\"\n",
    "pretrained_weights_path = os.path.join(load_depth_omnidata, f'omnidata_rgb2depth_dpt_hybrid.pth')\n",
    "\n",
    "checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n",
    "\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = {}\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        state_dict[k[6:]] = v\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "dpt_depth.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "count_parameters(dpt_depth.pretrained.model), dpt_depth.pretrained.model.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3538016",
   "metadata": {},
   "source": [
    "# ViT large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad2bcf",
   "metadata": {},
   "source": [
    "## timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d1df6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304715752, torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitl16res50 = timm.create_model(\"vit_large_patch16_384\", pretrained=True)\n",
    "count_parameters(vitl16res50), vitl16res50.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe39c1",
   "metadata": {},
   "source": [
    "## DPT (Omnidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b92c975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304715752, torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dpt.dpt_depth import DPTDepthModel\n",
    "\n",
    "backbone = 'vitl16_384'\n",
    "dpt_depth = DPTDepthModel(backbone=backbone)\n",
    "\n",
    "load_depth_omnidata = 'dpt/pretrained_models'\n",
    "assert os.path.exists(load_depth_omnidata), f\"Path doesn't exist: {load_depth_omnidata}!\"\n",
    "pretrained_weights_path = os.path.join(load_depth_omnidata, f'omnidata_rgb2depth_dpt_large.pth')\n",
    "\n",
    "checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n",
    "\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = {}\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        state_dict[k[6:]] = v\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "dpt_depth.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "count_parameters(dpt_depth.pretrained.model), dpt_depth.pretrained.model.forward_features(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5e645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
